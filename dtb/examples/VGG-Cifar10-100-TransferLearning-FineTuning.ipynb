{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's see how to use DBT to:\n",
    "# 1: train a VGG-like network on CIFAR-10\n",
    "# 2: continue a train from the last iteration\n",
    "# 3: do TRANSFER LEARNING from the trained model to another model that will be able to classify CIFAR-100\n",
    "# 4: do FINE TUNING of the model trained on CIFAR-10 to solve the CIFAR-100 classification problem\n",
    "# 5: compare the train/validation/test performance of the models\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from dytb.inputs.predefined import Cifar10, Cifar100\n",
    "from dytb.train import train\n",
    "from dytb.models.predefined.VGG import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "vgg = VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the CIFAR-10 input source\n",
    "cifar10 = Cifar10.Cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-24 16:39:55.738164: step 0, loss = 2.4898 (21.8 examples/sec; 2.294 sec/batch)\n",
      "2017-03-24 16:40:01.599543: step 100, loss = 2.1912 (895.4 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:07.363273: step 200, loss = 1.9165 (887.7 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:13.146663: step 300, loss = 1.9434 (897.0 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:18.899361: step 400, loss = 1.8396 (888.5 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:24.673581: step 500, loss = 1.8630 (895.4 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:30.474606: step 600, loss = 1.7952 (882.7 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:40:36.266451: step 700, loss = 1.8256 (887.0 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:42.076769: step 800, loss = 1.6266 (886.4 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:47.909738: step 900, loss = 1.5489 (894.9 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:40:53.753567: step 1000, loss = 1.7377 (882.7 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:40:57.476390 (1): train accuracy = 0.440 validation accuracy = 0.418\n"
     ]
    }
   ],
   "source": [
    "# 1: Train VGG on Cifar10 for an Epoch\n",
    "\n",
    "# Place the train process on GPU:0\n",
    "device = '/gpu:0'\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.42032</td>\n",
       "      <td>0.4184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test    train  validation\n",
       "accuracy  0.4184  0.42032      0.4184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Info containes every information related to the trained model.\n",
    "# We're interested in stats only, thus we extract only them from the info dict\n",
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "\n",
    "# Extract the accuracyes measured in every set (train/validation/test)\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2063</td>\n",
       "      <td>6</td>\n",
       "      <td>399</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>341</td>\n",
       "      <td>1502</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>802</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>314</td>\n",
       "      <td>378</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>558</td>\n",
       "      <td>551</td>\n",
       "      <td>659</td>\n",
       "      <td>597</td>\n",
       "      <td>1786</td>\n",
       "      <td>395</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>939</td>\n",
       "      <td>238</td>\n",
       "      <td>2024</td>\n",
       "      <td>1160</td>\n",
       "      <td>346</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>963</td>\n",
       "      <td>145</td>\n",
       "      <td>2388</td>\n",
       "      <td>796</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>706</td>\n",
       "      <td>251</td>\n",
       "      <td>2555</td>\n",
       "      <td>958</td>\n",
       "      <td>367</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>362</td>\n",
       "      <td>204</td>\n",
       "      <td>300</td>\n",
       "      <td>3857</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>270</td>\n",
       "      <td>651</td>\n",
       "      <td>451</td>\n",
       "      <td>475</td>\n",
       "      <td>2962</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1076</td>\n",
       "      <td>17</td>\n",
       "      <td>233</td>\n",
       "      <td>127</td>\n",
       "      <td>39</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>79</td>\n",
       "      <td>3101</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>193</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>130</td>\n",
       "      <td>116</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>626</td>\n",
       "      <td>337</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4     5     6     7     8     9\n",
       "0  2063    6  399  169  172    96    86   341  1502   164\n",
       "1   140  802   63   67   58    41    52   314   378  3148\n",
       "2   382    0  558  551  659   597  1786   395    47    19\n",
       "3   101    0  217  939  238  2024  1160   346     8    36\n",
       "4   161    0  230  237  963   145  2388   796    11    13\n",
       "5    32    0  131  706  251  2555   958   367     5    16\n",
       "6    36    0   95  362  204   300  3857   118     5    23\n",
       "7    46    0   81  270  651   451   475  2962     6    33\n",
       "8  1076   17  233  127   39    67    49    79  3101   185\n",
       "9   193   64   81  130  116    95   100   626   337  3221"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the confusion matrices \n",
    "confusion_matrices = {key: value[\"confusion_matrix\"] for key, value in info[\"stats\"].items()}\n",
    "# Display the confusione matrices for the training set\n",
    "df = pd.DataFrame(confusion_matrices[\"train\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-24 16:41:54.541918: step 1100, loss = 1.5129 (870.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:00.511865: step 1200, loss = 1.5524 (876.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:06.363273: step 1300, loss = 1.6666 (876.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:12.195253: step 1400, loss = 1.4128 (881.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:18.016253: step 1500, loss = 1.4976 (876.5 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:23.834454: step 1600, loss = 1.1128 (878.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:29.652662: step 1700, loss = 1.1047 (884.4 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:35.477904: step 1800, loss = 1.2570 (857.0 examples/sec; 0.058 sec/batch)\n",
      "2017-03-24 16:42:41.317559: step 1900, loss = 1.0597 (877.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:47.170549: step 2000, loss = 1.1177 (877.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:42:50.963063 (2): train accuracy = 0.640 validation accuracy = 0.609\n"
     ]
    }
   ],
   "source": [
    "# 2: train it again for another epoch\n",
    "# Note the `force_restart` parameter removed.\n",
    "# `epochs` is the TOTAL number of epoch for the trained model\n",
    "# Thus since we trained it before for a single epoch,\n",
    "# we set \"epochs\": 2 in order to train it for another epoch\n",
    "\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 2,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.62098</td>\n",
       "      <td>0.6092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test    train  validation\n",
       "accuracy  0.6092  0.62098      0.6092"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save last trained model info\n",
    "vggInfo = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-24 16:43:43.683366: step 0, loss = 4.8052 (29.3 examples/sec; 1.706 sec/batch)\n",
      "2017-03-24 16:43:49.694822: step 100, loss = 4.6455 (875.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:43:55.605838: step 200, loss = 4.6465 (873.1 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:01.482621: step 300, loss = 4.6347 (870.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:07.348843: step 400, loss = 4.6364 (878.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:13.226265: step 500, loss = 4.6301 (876.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:19.098956: step 600, loss = 4.6263 (878.5 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:24.959186: step 700, loss = 4.6244 (882.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:30.792740: step 800, loss = 4.6268 (888.5 examples/sec; 0.056 sec/batch)\n",
      "2017-03-24 16:44:36.677475: step 900, loss = 4.6200 (872.5 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:42.553147: step 1000, loss = 4.6147 (876.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:44:46.418681 (1): train accuracy = 0.000 validation accuracy = 0.010\n"
     ]
    }
   ],
   "source": [
    "# 3: TRANSFER LEARNING\n",
    "# Use the best model trained on Cifar10, to classify Cifar 100 images.\n",
    "# Thus we train ONLY the softmax linear scope (that has 100 neurons, now),\n",
    "# keeping constant any other previosly trained layer\n",
    "# We load the weights from the previous trained model, or better\n",
    "# DyTB saves the \"best\" model (w.r.t. a metric) in a separate folder\n",
    "# So we extract the info[\"paths\"][\"best\"] path, that's the path of the best\n",
    "# model trained so far.\n",
    "cifar100 = Cifar100.Cifar100()\n",
    "with tf.device(device):\n",
    "    transferInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                    }\n",
    "                }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\",\n",
    "            \"trainable_scopes\": \"VGG/softmax_linear\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-24 16:45:39.587934: step 0, loss = 4.8366 (31.3 examples/sec; 1.598 sec/batch)\n",
      "2017-03-24 16:45:45.607712: step 100, loss = 4.6532 (875.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:45:51.431524: step 200, loss = 4.6394 (882.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:45:57.311907: step 300, loss = 4.6367 (873.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:03.182901: step 400, loss = 4.6375 (879.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:09.049887: step 500, loss = 4.6347 (880.4 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:14.878901: step 600, loss = 4.6308 (882.5 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:20.715646: step 700, loss = 4.6263 (878.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:26.543737: step 800, loss = 4.6249 (879.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:32.418109: step 900, loss = 4.6243 (881.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:38.268707: step 1000, loss = 4.6169 (877.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-24 16:46:42.070421 (1): train accuracy = 0.020 validation accuracy = 0.010\n"
     ]
    }
   ],
   "source": [
    "# 4: FINE TUNING:\n",
    "# Use the model pointed by vggInfo to fine tune the whole network\n",
    "# and tune it on Cifar100.\n",
    "# Let's retrain the whole network end-to-end, starting from the learned weights\n",
    "# Just remove the \"traiable_scopes\" section from the surgery parameter\n",
    "with tf.device(device):\n",
    "    fineTuningInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01006</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test    train  validation\n",
       "accuracy  0.01  0.01006        0.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the performance of Transfer learning and Fine Tuning\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in transferInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01024</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test    train  validation\n",
       "accuracy  0.01  0.01024        0.01"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {key: value[\"accuracy\"] for key, value in fineTuningInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'args': {   'batch_size': 50,\n",
      "                'checkpoint_path': '',\n",
      "                'comment': '',\n",
      "                'dataset': <dytb.inputs.predefined.Cifar10.Cifar10 object at 0x7f3f642650b8>,\n",
      "                'epochs': 2,\n",
      "                'exclude_scopes': '',\n",
      "                'force_restart': False,\n",
      "                'gd': {   'args': {   'beta1': 0.9,\n",
      "                                      'beta2': 0.99,\n",
      "                                      'epsilon': 1e-08,\n",
      "                                      'learning_rate': 0.001},\n",
      "                          'optimizer': <class 'tensorflow.python.training.adam.AdamOptimizer'>},\n",
      "                'lr_decay': {'enabled': False, 'epochs': 25, 'factor': 0.1},\n",
      "                'model': <dytb.models.predefined.VGG.VGG object at 0x7f3f642c6f98>,\n",
      "                'regularizations': {   'augmentation': <function random_flip_left_right at 0x7f3f0db04c80>,\n",
      "                                       'l2': 1e-05},\n",
      "                'trainable_scopes': ''},\n",
      "    'paths': {   'best': '/data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best',\n",
      "                 'current': '/data/pgaleone/dtb_work/examples',\n",
      "                 'log': '/data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr'},\n",
      "    'stats': {   'test': {   'accuracy': 0.60919998481869697,\n",
      "                             'confusion_matrix': array([[554,  45,  85,  14,  20,   0,  13,  40, 159,  70],\n",
      "       [  5, 858,   1,   4,   0,   0,   3,   4,   3, 122],\n",
      "       [ 62,   4, 280, 145, 198,  69, 117,  85,  24,  16],\n",
      "       [  9,  11,  51, 356,  52, 246,  90, 125,  16,  44],\n",
      "       [ 19,   2,  56,  74, 487,  18,  95, 222,  14,  13],\n",
      "       [  3,   3,  41, 202,  37, 514,  25, 153,   8,  14],\n",
      "       [  2,   2,  13, 113,  84,  13, 737,  22,   5,   9],\n",
      "       [  7,   1,  20,  42,  43,  53,   8, 801,   0,  25],\n",
      "       [ 81, 164,  12,  15,   2,   4,   3,  10, 658,  51],\n",
      "       [ 14,  90,   4,  11,   3,   0,   1,  19,  11, 847]])},\n",
      "                 'train': {   'accuracy': 0.62097998225688933,\n",
      "                              'confusion_matrix': array([[2814,  211,  414,   75,  103,   15,   47,  234,  738,  381],\n",
      "       [  17, 4368,    4,   24,    2,    0,   15,   18,   31,  542],\n",
      "       [ 309,   26, 1518,  671, 1036,  256,  508,  447,   97,  113],\n",
      "       [  51,   38,  217, 1839,  219, 1279,  420,  691,   59,  152],\n",
      "       [ 125,   18,  280,  352, 2546,   75,  372, 1153,   37,   56],\n",
      "       [   9,   15,  137, 1055,  239, 2525,   96,  787,   21,   76],\n",
      "       [   9,   36,   58,  576,  381,   59, 3751,   83,   24,   52],\n",
      "       [  28,    5,   76,  213,  208,  252,   13, 4042,    7,  131],\n",
      "       [ 416,  769,   69,   60,    8,    9,   27,   50, 3336,  250],\n",
      "       [  61,  368,    7,   47,    6,    8,   10,  102,   50, 4370]])},\n",
      "                 'validation': {   'accuracy': 0.60919998422265054,\n",
      "                                   'confusion_matrix': array([[554,  45,  85,  14,  20,   0,  13,  40, 159,  70],\n",
      "       [  5, 858,   1,   4,   0,   0,   3,   4,   3, 122],\n",
      "       [ 62,   4, 280, 145, 198,  69, 117,  85,  24,  16],\n",
      "       [  9,  11,  51, 356,  52, 246,  90, 125,  16,  44],\n",
      "       [ 19,   2,  56,  74, 487,  18,  95, 222,  14,  13],\n",
      "       [  3,   3,  41, 202,  37, 514,  25, 153,   8,  14],\n",
      "       [  2,   2,  13, 113,  84,  13, 737,  22,   5,   9],\n",
      "       [  7,   1,  20,  42,  43,  53,   8, 801,   0,  25],\n",
      "       [ 81, 164,  12,  15,   2,   4,   3,  10, 658,  51],\n",
      "       [ 14,  90,   4,  11,   3,   0,   1,  19,  11, 847]])}},\n",
      "    'steps': {'decay': 25000, 'epoch': 1000, 'log': 100, 'max': 2000}}\n"
     ]
    }
   ],
   "source": [
    "# For completeness, lets see what a info object contains\n",
    "pprint.pprint(info, indent=4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
